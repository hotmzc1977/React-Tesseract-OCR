[{"D:\\Projects\\github\\react-tesseract-ocr\\src\\index.tsx":"1","D:\\Projects\\github\\react-tesseract-ocr\\src\\App.tsx":"2","D:\\Projects\\github\\react-tesseract-ocr\\src\\OCR.tsx":"3"},{"size":155,"mtime":1668826419108,"results":"4","hashOfConfig":"5"},{"size":1264,"mtime":1668840665744,"results":"6","hashOfConfig":"5"},{"size":27878,"mtime":1668826419107,"results":"7","hashOfConfig":"5"},{"filePath":"8","messages":"9","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"10"},"18gb76k",{"filePath":"11","messages":"12","errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"13","messages":"14","errorCount":0,"fatalErrorCount":0,"warningCount":25,"fixableErrorCount":0,"fixableWarningCount":0,"source":"15","usedDeprecatedRules":"10"},"D:\\Projects\\github\\react-tesseract-ocr\\src\\index.tsx",[],["16","17"],"D:\\Projects\\github\\react-tesseract-ocr\\src\\App.tsx",["18","19","20"],"D:\\Projects\\github\\react-tesseract-ocr\\src\\OCR.tsx",["21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45"],"import { useCallback, useEffect, useRef, useState } from \"react\";\r\nimport { Stream } from \"stream\";\r\nimport Cropper from 'react-cropper'\r\nimport \"cropperjs/dist/cropper.css\";\r\nimport { Box, CircularProgress, Fab, FormControlLabel, Grid, Icon, IconButton, Switch, TextField, Tooltip, Typography } from \"@mui/material\";\r\nimport Tesseract, { RecognizeResult } from 'tesseract.js';\r\nimport PhotoCameraIcon from '@mui/icons-material/PhotoCamera';\r\nimport ZoomInIcon from '@mui/icons-material/ZoomIn';\r\nimport ZoomOutIcon from '@mui/icons-material/ZoomOut';\r\nimport FileUploadIcon from '@mui/icons-material/FileUpload';\r\nimport HighlightAltIcon from '@mui/icons-material/HighlightAlt';\r\nimport DeleteForeverIcon from '@mui/icons-material/DeleteForever';\r\nimport PlayCircleIcon from '@mui/icons-material/PlayCircle';\r\nimport DeselectIcon from '@mui/icons-material/Deselect';\r\nimport FormatShapesIcon from '@mui/icons-material/FormatShapes';\r\nimport LineStyleIcon from '@mui/icons-material/LineStyle';\r\nimport HdrAutoIcon from '@mui/icons-material/HdrAuto';\r\nimport CenterFocusStrongIcon from '@mui/icons-material/CenterFocusStrong';\r\nimport { fontSize } from \"@mui/system\";\r\n\r\ntype Position = {\r\n    top: number,\r\n    left: number\r\n}\r\n\r\ntype Size = {\r\n    width: number,\r\n    height: number\r\n}\r\n\r\ntype ResultMode = \"line\" | \"word\" | \"paragraph\"\r\ntype DisplayMode = \"camera\" | \"crop\" | \"recognize\"\r\n\r\ntype RecognizeImageResult = { success: boolean, result?: Tesseract.RecognizeResult, error?: any }\r\n\r\ntype TesseractBlock = Tesseract.Line | Tesseract.Word | Tesseract.Paragraph\r\n\r\ninterface Props {\r\n    size?: Size\r\n    language?: string,\r\n    cropArea?: Position & Size\r\n    videcropHeightRatio?: number,\r\n    confidence?: number\r\n    resultMode?: ResultMode\r\n    onSelect?: (text: string) => Promise<void>\r\n    onExamineResult?: (result: Tesseract.RecognizeResult) => Promise<boolean>\r\n}\r\n\r\nexport default function OCR(props: Props) {\r\n    const [OCRSize, setOCRSize] = useState<Size>(props.size ?? { width: window.screen.width * 0.95, height: window.screen.height * 0.75 })\r\n    const [language] = useState(props.language ?? \"eng\")\r\n    const [upperPanelPosAndSize, setUpperPanelPosAndSize] = useState<Position & Size>()\r\n    const [lowerPanelPosAndSize, setLowerPanelPosAndSize] = useState<Position & Size>()\r\n    const [videcropHeightRatio, setCropHeightPercent] = useState(() => props.videcropHeightRatio ? (props.videcropHeightRatio > 1 ? 1 : props.videcropHeightRatio) : 0.2)\r\n    const [videoOffsetPosAndSize, setVideoOffsetPosAndSize] = useState<Position & Size>()\r\n    const [videoSize, setVideoSize] = useState<Size>()\r\n    const [videoZoom, setVideoZoom] = useState(1)\r\n    const [cropArea, setCropArea] = useState<Position & Size>()\r\n    const [cameras, setCameras] = useState<MediaDeviceInfo[]>([]);\r\n    const inputRef = useRef<HTMLInputElement>(null);\r\n    const [imageSrc, setImageSrc] = useState<string>()\r\n\r\n    const [cropData, setCropData] = useState<string>();\r\n    const [cropDataPreview, setCropDataPreview] = useState<string>();\r\n    const [cropper, setCropper] = useState<Cropper>();\r\n    const [text, setText] = useState<any>()\r\n    const [result, setResult] = useState<RecognizeImageResult>()\r\n    const [zoomCropData, setZoomCropData] = useState(1)\r\n    const [zoomImageSrc, setZoomImageSrc] = useState(1)\r\n    const [scenario, setScenario] = useState<DisplayMode>(\"camera\")\r\n    const [resultMode, setResultMode] = useState<ResultMode>(props.resultMode ?? \"line\")\r\n    const [progress, setProgress] = useState(0)\r\n    //const [progressStatus, setProgressStatus] = useState(\"\")\r\n    const [selectedBox, setSelectedBox] = useState(\"\")\r\n    const [confidence] = useState(props.confidence ?? 20)\r\n    const previewCanvasRef = useRef<HTMLCanvasElement>(null)\r\n    const [autoMode, setAutoMode] = useState<boolean>(false)\r\n\r\n    const processingRef = useRef<boolean>(false)\r\n    const intervalRef = useRef<any>(null)\r\n    const videoRef = useRef<HTMLVideoElement | null>(null);\r\n    const streamRef = useRef<MediaStream>()\r\n    const workerRef = useRef<Tesseract.Worker>()\r\n    const imageRef = useRef<HTMLImageElement>(null)\r\n\r\n    useEffect(() => {\r\n        if (videoOffsetPosAndSize && videoSize) {\r\n            const panelHeight = videoOffsetPosAndSize.height * (1 - videcropHeightRatio) / 2\r\n            videoOffsetPosAndSize.left === 0 && setUpperPanelPosAndSize({\r\n                top: videoOffsetPosAndSize.top,\r\n                left: videoOffsetPosAndSize.left,\r\n                width: videoOffsetPosAndSize.width,\r\n                height: panelHeight\r\n            })\r\n            videoOffsetPosAndSize.left === 0 && setLowerPanelPosAndSize({\r\n                top: videoOffsetPosAndSize.height - panelHeight,\r\n                left: videoOffsetPosAndSize.left,\r\n                width: videoOffsetPosAndSize.width,\r\n                height: panelHeight\r\n            })\r\n            setCropArea({\r\n                top: videoSize.height * (1 - videcropHeightRatio) / 2,\r\n                left: 0,\r\n                width: videoSize.width,\r\n                height: videoSize.height * videcropHeightRatio\r\n            })\r\n        }\r\n    }, [videoOffsetPosAndSize, videoSize, videoZoom, videcropHeightRatio])\r\n\r\n    const fileToBase64 = async (file: Blob) => new Promise((resolve, reject) => {\r\n        const reader = new FileReader();\r\n        reader.readAsDataURL(file);\r\n        reader.onload = () => resolve(reader.result);\r\n        reader.onerror = error => reject(error);\r\n    });\r\n\r\n    const cropImageInSelectedAreaFromVideo = async (cropArea: Position & Size) => {\r\n        if (!previewCanvasRef.current || !videoRef.current) return\r\n        previewCanvasRef.current.height = cropArea.height;\r\n        previewCanvasRef.current.width = cropArea.width\r\n        const ctx = previewCanvasRef.current.getContext('2d');\r\n        const { top, left, height, width } = cropArea;\r\n        //console.log(videoRef.current.videoHeight, videoRef.current.videoWidth, videoRef.current.height, videoRef.current.width)\r\n        if (ctx) {\r\n            // ctx.clearRect(0, 0, videoSize!.width, videoSize!.height);\r\n            // ctx.fillStyle = \"rgba(255, 255, 255,1)\";\r\n            // ctx.fillRect(0, 0, videoSize!.width, videoSize!.height);\r\n            ctx!.drawImage(\r\n                videoRef.current,\r\n                left,\r\n                top,\r\n                width,\r\n                height,\r\n                0,\r\n                0,\r\n                width,\r\n                height\r\n            );\r\n            let newimgUri = previewCanvasRef.current.toDataURL().toString();\r\n            return newimgUri;\r\n        }\r\n    }\r\n\r\n    const updateImageSrc = async (image: string, copyToCropDate?: boolean) => {\r\n        const imgSize = await getImageSize(image);\r\n        const zoom = calculateZoom(imgSize, OCRSize);\r\n        setImageSrc(image);\r\n        setZoomImageSrc(zoom)\r\n        if (copyToCropDate) {\r\n            setCropData(image);\r\n            setZoomCropData(zoom)\r\n            setResult(await processImage(image))\r\n        }\r\n    }\r\n\r\n    const updateCropData = async (imageUrl: string, updateOnly?: boolean) => {\r\n        const imgSize = await getImageSize(imageUrl)\r\n        const zoom = calculateZoom(imgSize, OCRSize)\r\n        setCropData(imageUrl);\r\n        //setCropDataSize(imgSize)\r\n        setZoomCropData(zoom)\r\n        !updateOnly && setResult(await processImage(imageUrl))\r\n    }\r\n\r\n    const getImageSize = async (imgBase64: string): Promise<Size> => {\r\n        let img = new Image()\r\n        img.src = imgBase64\r\n        await img.decode()\r\n        return { width: img.naturalWidth, height: img.naturalHeight }\r\n    }\r\n\r\n    const calculateZoom = (imageSize: Size, canvasSize: Size) => {\r\n        if (canvasSize.height >= imageSize.height && canvasSize.width >= imageSize.width) {\r\n            return 1\r\n        }\r\n        else {\r\n            const xScale = canvasSize.width / imageSize.width\r\n            const yScale = canvasSize.height / imageSize.height\r\n            return xScale > yScale ? yScale : xScale\r\n        }\r\n    }\r\n\r\n    const onInputChange = async () => {\r\n        const files = inputRef.current?.files;\r\n        if (files && files.length > 0) {\r\n            //const imageUrl = URL.createObjectURL(files[0])\r\n            setScenario(\"recognize\")\r\n            const imageBase64 = await fileToBase64(files[0])\r\n            await updateImageSrc(imageBase64 as string, true)\r\n\r\n        }\r\n        else {\r\n            setImageSrc(undefined);\r\n        }\r\n    }\r\n\r\n    const onOCRClicked = async () => {\r\n        if (autoMode) return;\r\n        if (scenario === \"camera\") {\r\n            const fullImage = await cropImageInSelectedAreaFromVideo({ ...videoSize!, top: 0, left: 0 })\r\n            fullImage && updateImageSrc(fullImage)\r\n            const cropImage = await cropImageInSelectedAreaFromVideo(cropArea!)\r\n            cropImage && updateCropData(cropImage)\r\n            setResult(undefined)\r\n            setScenario(\"recognize\")\r\n        }\r\n\r\n        else if (scenario === \"crop\" && cropper) {\r\n            cropper.getCroppedCanvas().toBlob(async (blob: Blob | null) => {\r\n                if (blob) {\r\n                    const image = await fileToBase64(blob)\r\n                    updateCropData(image as string);\r\n                    setScenario(\"recognize\")\r\n                }\r\n            })\r\n        }\r\n        else {\r\n            cropData && setResult(await processImage(cropData))\r\n        }\r\n    }\r\n\r\n    const processImage = async (image: string): Promise<RecognizeImageResult> => {\r\n        return workerRef.current!.recognize(image)\r\n            .then((result: RecognizeResult) => {\r\n                console.log(\"result\", result);\r\n                setProgress(1);\r\n                return { success: true, result };\r\n            })\r\n            .catch((err: any) => {\r\n                console.error(\"recognize\", err);\r\n                return { success: false, error: err };\r\n            });\r\n\r\n    }\r\n\r\n    const zoomIn = () => {\r\n        if (scenario === \"recognize\") {\r\n            setZoomCropData(zoom => zoom + 0.1)\r\n        }\r\n        else if (scenario === \"crop\") {\r\n            setZoomImageSrc(zoom => zoom + 0.1)\r\n        }\r\n    }\r\n\r\n    const zoomOut = () => {\r\n        if (scenario === \"recognize\") {\r\n            setZoomCropData(zoom => zoom - 0.1)\r\n        }\r\n        else if (scenario === \"crop\") {\r\n            setZoomImageSrc(zoom => zoom - 0.1)\r\n        }\r\n    }\r\n\r\n    const onDeleteClicked = () => {\r\n        setScenario(\"camera\")\r\n        setImageSrc(undefined)\r\n        setCropData(undefined)\r\n        setResult(undefined)\r\n    }\r\n\r\n    const onStyleChanged = () => {\r\n        if (resultMode === \"line\") {\r\n            setResultMode(\"paragraph\")\r\n        }\r\n        else if (resultMode === \"paragraph\") {\r\n            setResultMode(\"word\")\r\n        }\r\n        else {\r\n            setResultMode(\"line\")\r\n        }\r\n    }\r\n\r\n    const drawBBox = (blocks: (Tesseract.Line | Tesseract.Word | Tesseract.Paragraph)[]) => {\r\n\r\n        return blocks.map((item, index) => {\r\n            const key = `${resultMode}-${index}`\r\n\r\n            return item.confidence > confidence ? <div key={key} id={key}\r\n                onClick={async () => {\r\n                    if (key === selectedBox) {\r\n                        setSelectedBox('');\r\n                        setText('')\r\n                        props.onSelect && await props.onSelect('')\r\n                    }\r\n                    else {\r\n                        setSelectedBox(key);\r\n                        setText(item.text)\r\n                        props.onSelect && await props.onSelect(item.text)\r\n                    }\r\n                }}\r\n                style={{\r\n                    position: \"absolute\",\r\n                    left: item.bbox.x0 * (autoMode ? videoZoom : zoomCropData) + (autoMode ? 0 : (OCRSize.width - (zoomCropData * (imageRef.current?.offsetWidth ?? 0))) / 2),\r\n                    top: autoMode ? (item.bbox.y0 + ((videoSize?.height ?? 0) - (cropArea?.height ?? 0)) / 2) * videoZoom : item.bbox.y0 * zoomCropData,\r\n                    width: (item.bbox.x1 - item.bbox.x0) * (autoMode ? videoZoom : zoomCropData),\r\n                    height: (item.bbox.y1 - item.bbox.y0) * (autoMode ? videoZoom : zoomCropData),\r\n                    border: selectedBox === key ? \"1px solid green\" : \"1px dashed red\",\r\n                    backgroundColor: \"transparent\",\r\n                    color: \"red\",\r\n                    overflow: \"visible\"\r\n                }}> <div style={{ position: \"relative\", overflow: \"visible\", height: \"100%\" }}>\r\n                    <div style={{ position: \"absolute\", width: \"80%\", bottom: \"100%\", color: \"#fb4d3d\", overflow: \"hidden\", fontSize: \"10px\", display: \"block\", whiteSpace: \"nowrap\" }}>\r\n                        {item.text}\r\n                    </div>\r\n                </div>\r\n            </div > : null\r\n\r\n        })\r\n    }\r\n\r\n    const onFileUploadClick = () => {\r\n        if (inputRef.current) {\r\n            inputRef.current.click();\r\n            inputRef.current.files = null\r\n        }\r\n    }\r\n\r\n\r\n\r\n    useEffect(() => {\r\n        if (autoMode && !intervalRef.current) {\r\n            intervalRef.current = setInterval(async () => {\r\n                if (!processingRef.current) {\r\n                    processingRef.current = true\r\n                    const image = await cropImageInSelectedAreaFromVideo(cropArea!)\r\n                    if (image) {\r\n                        setCropDataPreview(image)\r\n                        const result = await processImage(image as any)\r\n                        setResult(result)\r\n                        if (props.onExamineResult && result.result && await props.onExamineResult(result.result)) {\r\n                            await updateCropData(image, true)\r\n                            setScenario(\"recognize\")\r\n                            setAutoMode(false)\r\n                            return;\r\n                        }\r\n                    }\r\n                    setTimeout(() => {\r\n                        processingRef.current = false\r\n                    }, 100);\r\n                }\r\n            }, 100)\r\n            console.log(\"intervalRef.current.set\", intervalRef.current)\r\n        }\r\n        else {\r\n            console.log(\"intervalRef.current.clear\", intervalRef.current)\r\n            processingRef.current = false\r\n            intervalRef.current && clearInterval(intervalRef.current)\r\n            intervalRef.current = null;\r\n        }\r\n    }, [autoMode])\r\n\r\n    const playVideo = async () => {\r\n        try {\r\n            const stream: MediaStream = await navigator.mediaDevices.getUserMedia({\r\n                audio: false,\r\n                video: {\r\n                    facingMode: \"environment\"\r\n                }\r\n            })\r\n            if (videoRef.current && stream) {\r\n                videoRef.current.srcObject = stream;\r\n                // videoRef.current.onloadedmetadata = () => {\r\n                //     setVideoSize({\r\n                //         width: videoRef.current!.videoWidth,\r\n                //         height: videoRef.current!.videoHeight\r\n                //     })\r\n                //     setVideoOffsetPosAndSize({\r\n                //         top: videoRef.current!.offsetTop,\r\n                //         left: videoRef.current!.offsetLeft,\r\n                //         width: videoRef.current!.offsetWidth,\r\n                //         height: videoRef.current!.offsetHeight\r\n                //     })\r\n                //     setVideoZoom(videoRef.current!.offsetHeight / videoRef.current!.videoHeight)\r\n                // }\r\n                streamRef.current = stream\r\n                videoRef.current.play().then(() => {\r\n                    setVideoSize({\r\n                        width: videoRef.current!.videoWidth,\r\n                        height: videoRef.current!.videoHeight\r\n                    })\r\n                    setVideoOffsetPosAndSize({\r\n                        top: videoRef.current!.offsetTop,\r\n                        left: videoRef.current!.offsetLeft,\r\n                        width: videoRef.current!.offsetWidth,\r\n                        height: videoRef.current!.offsetHeight\r\n                    })\r\n                    setVideoZoom(videoRef.current!.offsetHeight / videoRef.current!.videoHeight)\r\n                    setOCRSize({ height: videoRef.current!.offsetHeight + 100, width: Math.min(videoRef.current!.offsetWidth, OCRSize.width) })\r\n                })\r\n            }\r\n        }\r\n        catch (err: any) {\r\n            console.log(err.toString())\r\n        }\r\n\r\n    }\r\n\r\n    const stopVideo = () => {\r\n        streamRef && streamRef.current && streamRef.current.getTracks().forEach((track: any) => {\r\n            track.stop();\r\n        })\r\n        console.log(\"video stop\")\r\n    }\r\n\r\n    useEffect(() => {\r\n        console.log(\"videoSize\", videoSize, videoRef.current?.offsetHeight, videoRef.current?.offsetWidth, videoRef.current?.offsetTop, videoRef.current?.offsetLeft, videoRef.current?.offsetParent)\r\n        console.log(\"cropArea\", cropArea)\r\n    }, [videoSize])\r\n\r\n    const initialize = async () => {\r\n\r\n        workerRef.current = Tesseract.createWorker({\r\n            logger: (m: any) => {\r\n                console.log(m);\r\n                //setProcessStatus(m);\r\n                //setProgressStatus(m.status);\r\n                if (m.status === \"recognizing text\") {\r\n                    setProgress(m.progress < 0.02 ? 0.02 : m.progress);\r\n                }\r\n                else {\r\n                    setProgress(0.01);\r\n                }\r\n            },\r\n        });\r\n        await workerRef.current.load();\r\n        await workerRef.current.loadLanguage(language);\r\n        await workerRef.current.initialize(language);\r\n        await playVideo()\r\n        setScenario(\"camera\")\r\n\r\n    }\r\n\r\n    const terminate = async () => {\r\n        workerRef.current && await workerRef.current.terminate()\r\n\r\n    }\r\n\r\n    useEffect(() => {\r\n        initialize()\r\n        return () => {\r\n            stopVideo();\r\n            terminate();\r\n        }\r\n    }, [])\r\n\r\n    useEffect(() => {\r\n        if (scenario === \"camera\") {\r\n            playVideo()\r\n        }\r\n        else {\r\n            stopVideo()\r\n        }\r\n    }, [scenario])\r\n\r\n    return (\r\n        <Box style={{ height: OCRSize.height, width: OCRSize.width, position: \"relative\", border: \"1px solid Black\", backgroundColor: \"black\", opacity: \"0.8\", margin: \"auto\" }}>\r\n            <Box style={{ position: \"absolute\", left: 0, right: 0, top: 0, bottom: 0 }} >\r\n                <Box style={{ position: \"relative\", overflow: \"visible\" }}>\r\n                    {/* {\r\n                        scenario === \"camera\" && <Webcam\r\n                            audio={false}\r\n                            ref={webcamRef}\r\n                            screenshotFormat=\"image/jpeg\"\r\n                            width={OCRSize.width}\r\n                            height={OCRSize.height}\r\n                            videoConstraints={{\r\n                                // deviceId: cameraDeviceId,\r\n                                facingMode: \"environment\",\r\n                                height: OCRSize.height,\r\n                                width: OCRSize.width,\r\n                            }}\r\n\r\n                        />\r\n                    } */}\r\n\r\n\r\n                    {scenario === \"camera\" && <video\r\n                        ref={videoRef}\r\n                        autoPlay\r\n                        muted\r\n                        playsInline\r\n                        style={{\r\n                            maxWidth: OCRSize.width\r\n                        }}\r\n                    // style={{ position: \"absolute\", top: 0, left: 0 }}\r\n                    ></video>}\r\n\r\n                    {/* {scenario === \"camera\" && <img\r\n                        style={{ zoom: zoomCropData }}\r\n                        src={cropData}\r\n                    />} */}\r\n\r\n\r\n                    {scenario === \"camera\" && upperPanelPosAndSize &&\r\n                        <Box style={{ ...upperPanelPosAndSize, position: \"absolute\", opacity: \"0.6\", background: \"green\" }} >\r\n                            {cropDataPreview && autoMode && <img src={cropDataPreview} style={{ maxWidth: \"100%\", maxHeight: \"100%\" }} />}\r\n                        </Box>\r\n                    }\r\n                    {scenario === \"camera\" && lowerPanelPosAndSize && <Box style={{ ...lowerPanelPosAndSize, position: \"absolute\", opacity: \"0.6\", background: \"green\" }} />}\r\n\r\n                    {scenario === \"crop\" && <Cropper\r\n                        height={OCRSize.height}\r\n                        width={OCRSize.width}\r\n                        zoomTo={zoomImageSrc}\r\n                        // preview=\".img-preview\"\r\n                        src={imageSrc}\r\n                        viewMode={1}\r\n                        minCropBoxHeight={10}\r\n                        minCropBoxWidth={10}\r\n                        background={false}\r\n                        responsive={true}\r\n                        // autoCropArea={1}\r\n                        checkOrientation={false} // https://github.com/fengyuanchen/cropperjs/issues/671\r\n                        onInitialized={(instance: Cropper) => {\r\n                            setCropper(instance);\r\n                        }}\r\n                        guides={true}\r\n                        style={{\r\n                            maxHeight: OCRSize.height,\r\n                            maxWidth: OCRSize.width\r\n                        }}\r\n                    />}\r\n\r\n\r\n                    {\r\n                        scenario === \"recognize\" && cropData &&\r\n                        <img ref={imageRef} style={{ zoom: zoomCropData }} src={cropData} alt=\"cropped\" />\r\n                    }\r\n                    <canvas ref={previewCanvasRef} hidden />\r\n\r\n                    {result && result.result && ((autoMode === false && progress === 1) || autoMode === true) &&\r\n                        drawBBox(resultMode === \"paragraph\" ? result.result.data.paragraphs : (resultMode === \"word\" ? result.result.data.words : result.result.data.lines))\r\n                    }\r\n\r\n                    {/* {autoMode === true && result && result.result &&\r\n                        drawBBox(resultMode === \"paragraph\" ? result.result.data.paragraphs : (resultMode === \"word\" ? result.result.data.words : result.result.data.lines))\r\n                    } */}\r\n\r\n\r\n                </Box>\r\n            </Box>\r\n            {\r\n                autoMode === false && scenario === \"recognize\" && progress > 0 && progress < 1 &&\r\n                <Box sx={{\r\n                    top: lowerPanelPosAndSize?.top ?? 0,\r\n                    left: 0,\r\n                    bottom: (lowerPanelPosAndSize?.height ?? 0) + (lowerPanelPosAndSize?.top ?? 0),\r\n                    right: 0,\r\n                    position: 'absolute',\r\n                    display: 'flex',\r\n                    alignItems: 'center',\r\n                    justifyContent: 'center',\r\n\r\n                }}>\r\n                    <Box sx={{ position: 'relative', display: 'inline-flex' }}>\r\n                        <CircularProgress size={25} variant=\"determinate\" value={100 * progress} />\r\n                        <Box\r\n                            sx={{\r\n                                top: 0,\r\n                                left: 0,\r\n                                bottom: 0,\r\n                                right: 0,\r\n                                position: 'absolute',\r\n                                display: 'inline-flex',\r\n                                alignItems: 'center',\r\n                                justifyContent: 'center',\r\n                            }}\r\n                        >\r\n                            <Typography\r\n                                variant=\"caption\"\r\n                                component=\"div\"\r\n                                color=\"text.secondary\"\r\n                                fontSize=\"20px\"\r\n                                sx={{ width: OCRSize.width }}\r\n                            >{`${Math.round(100 * progress)}%`}</Typography>\r\n\r\n                        </Box>\r\n                    </Box>\r\n                </Box>\r\n\r\n            }\r\n            {/* <Fab aria-label=\"Auto Mode\" onClick={() => setAutoMode(autoMode => !autoMode)} size=\"small\" style={{\r\n                position: 'absolute',\r\n                bottom: 5,\r\n                left: 5\r\n            }}>\r\n                <HdrAutoIcon color={autoMode ? undefined : \"disabled\"} />\r\n            </Fab> */}\r\n            {/* {\r\n                scenario === \"camera\" && <Fab color=\"default\" aria-label=\"add\" size=\"small\" style={{\r\n                    position: 'absolute',\r\n                    bottom: 20,\r\n                    left: 5\r\n                }} onClick={onCameraClicked}>\r\n                    <CenterFocusStrongIcon />\r\n                </Fab>\r\n            } */}\r\n            {/* {\r\n                <Fab aria-label=\"add\" size=\"small\" style={{\r\n                    position: 'absolute',\r\n                    bottom: 50,\r\n                    left: 5\r\n                }} onClick={onStyleChanged}>\r\n                    <LineStyleIcon />\r\n                </Fab>\r\n            } */}\r\n\r\n            {<Fab aria-label=\"add\" size=\"small\" style={{\r\n                position: 'absolute',\r\n                bottom: 50,\r\n                right: 5\r\n            }} onClick={onDeleteClicked}>\r\n                <DeleteForeverIcon />\r\n            </Fab>}\r\n\r\n            <Fab aria-label=\"upload\" size=\"small\" style={{\r\n                position: 'absolute',\r\n                bottom: 5,\r\n                right: 5\r\n            }} onClick={onFileUploadClick} >\r\n                <FileUploadIcon />\r\n            </Fab>\r\n\r\n            {<Fab onClick={() => { setScenario(\"crop\"); setResult(undefined) }} size=\"small\" style={{\r\n                position: 'absolute',\r\n                bottom: 95,\r\n                right: 5\r\n            }}>\r\n                <DeselectIcon />\r\n            </Fab>}\r\n\r\n            <Fab aria-label=\"Take Photo\" size=\"large\" onClick={onOCRClicked} style={{\r\n                position: 'absolute',\r\n                bottom: 5,\r\n                left: OCRSize.width / 2 - 28\r\n            }}>\r\n                <PhotoCameraIcon fontSize=\"large\" />\r\n            </Fab>\r\n\r\n            {<IconButton aria-label=\"Zoom In\" onClick={zoomIn} size=\"large\" style={{\r\n                position: 'absolute',\r\n                bottom: 0,\r\n                right: OCRSize.width / 2 - 100,\r\n            }} >\r\n                <ZoomInIcon fontSize=\"large\" color=\"info\" />\r\n            </IconButton>}\r\n            {<IconButton aria-label=\"Zoom Out\" onClick={zoomOut} size=\"large\" style={{\r\n                position: 'absolute',\r\n                bottom: 0,\r\n                left: OCRSize.width / 2 - 100,\r\n\r\n            }}>\r\n                <ZoomOutIcon fontSize=\"large\" color=\"info\" />\r\n            </IconButton>}\r\n\r\n            {/* <Fab aria-label=\"Crop\" onClick={() => setScenario(\"crop\")} size=\"small\" style={{\r\n                position: 'absolute',\r\n                bottom: 120,\r\n                left: 5\r\n            }}>\r\n                { <HighlightAltIcon />}\r\n            </Fab> */}\r\n\r\n            <Switch sx={{\r\n                position: 'absolute',\r\n                bottom: 5,\r\n                left: 5,\r\n                backgroundColor: \"white\",\r\n                margin: 0,\r\n                borderRadius: \"20px\",\r\n                fontSize: \"8px\"\r\n            }} color=\"secondary\" checked={autoMode} onChange={(_, checked: boolean) => setAutoMode(checked)}\r\n            />\r\n\r\n\r\n\r\n            <input\r\n                accept=\"images/*, image/*\"\r\n                ref={inputRef} type=\"file\"\r\n                onChange={onInputChange}\r\n                onClick={(event) => { (event.target as HTMLInputElement).value = '' }}\r\n                hidden />\r\n\r\n\r\n        </Box>\r\n    );\r\n}\r\n",{"ruleId":"46","replacedBy":"47"},{"ruleId":"48","replacedBy":"49"},{"ruleId":"50","severity":1,"message":"51","line":7,"column":10,"nodeType":"52","messageId":"53","endLine":7,"endColumn":18},{"ruleId":"50","severity":1,"message":"54","line":11,"column":9,"nodeType":"52","messageId":"53","endLine":11,"endColumn":20},{"ruleId":"50","severity":1,"message":"55","line":15,"column":9,"nodeType":"52","messageId":"53","endLine":15,"endColumn":20},{"ruleId":"50","severity":1,"message":"56","line":1,"column":10,"nodeType":"52","messageId":"53","endLine":1,"endColumn":21},{"ruleId":"50","severity":1,"message":"57","line":2,"column":10,"nodeType":"52","messageId":"53","endLine":2,"endColumn":16},{"ruleId":"50","severity":1,"message":"58","line":5,"column":38,"nodeType":"52","messageId":"53","endLine":5,"endColumn":54},{"ruleId":"50","severity":1,"message":"59","line":5,"column":56,"nodeType":"52","messageId":"53","endLine":5,"endColumn":60},{"ruleId":"50","severity":1,"message":"60","line":5,"column":62,"nodeType":"52","messageId":"53","endLine":5,"endColumn":66},{"ruleId":"50","severity":1,"message":"61","line":5,"column":88,"nodeType":"52","messageId":"53","endLine":5,"endColumn":97},{"ruleId":"50","severity":1,"message":"62","line":5,"column":99,"nodeType":"52","messageId":"53","endLine":5,"endColumn":106},{"ruleId":"50","severity":1,"message":"63","line":11,"column":8,"nodeType":"52","messageId":"53","endLine":11,"endColumn":24},{"ruleId":"50","severity":1,"message":"64","line":13,"column":8,"nodeType":"52","messageId":"53","endLine":13,"endColumn":22},{"ruleId":"50","severity":1,"message":"65","line":15,"column":8,"nodeType":"52","messageId":"53","endLine":15,"endColumn":24},{"ruleId":"50","severity":1,"message":"66","line":16,"column":8,"nodeType":"52","messageId":"53","endLine":16,"endColumn":21},{"ruleId":"50","severity":1,"message":"67","line":17,"column":8,"nodeType":"52","messageId":"53","endLine":17,"endColumn":19},{"ruleId":"50","severity":1,"message":"68","line":18,"column":8,"nodeType":"52","messageId":"53","endLine":18,"endColumn":29},{"ruleId":"50","severity":1,"message":"69","line":19,"column":10,"nodeType":"52","messageId":"53","endLine":19,"endColumn":18},{"ruleId":"50","severity":1,"message":"70","line":36,"column":6,"nodeType":"52","messageId":"53","endLine":36,"endColumn":20},{"ruleId":"50","severity":1,"message":"71","line":54,"column":33,"nodeType":"52","messageId":"53","endLine":54,"endColumn":53},{"ruleId":"50","severity":1,"message":"72","line":59,"column":12,"nodeType":"52","messageId":"53","endLine":59,"endColumn":19},{"ruleId":"50","severity":1,"message":"73","line":59,"column":21,"nodeType":"52","messageId":"53","endLine":59,"endColumn":31},{"ruleId":"50","severity":1,"message":"74","line":66,"column":12,"nodeType":"52","messageId":"53","endLine":66,"endColumn":16},{"ruleId":"50","severity":1,"message":"75","line":261,"column":11,"nodeType":"52","messageId":"53","endLine":261,"endColumn":25},{"ruleId":"76","severity":1,"message":"77","line":350,"column":8,"nodeType":"78","endLine":350,"endColumn":18,"suggestions":"79"},{"ruleId":"76","severity":1,"message":"80","line":408,"column":8,"nodeType":"78","endLine":408,"endColumn":19,"suggestions":"81"},{"ruleId":"76","severity":1,"message":"82","line":444,"column":8,"nodeType":"78","endLine":444,"endColumn":10,"suggestions":"83"},{"ruleId":"76","severity":1,"message":"84","line":453,"column":8,"nodeType":"78","endLine":453,"endColumn":18,"suggestions":"85"},{"ruleId":"86","severity":1,"message":"87","line":496,"column":61,"nodeType":"88","endLine":496,"endColumn":138},"no-native-reassign",["89"],"no-negated-in-lhs",["90"],"@typescript-eslint/no-unused-vars","'anchorEl' is assigned a value but never used.","Identifier","unusedVar","'handleClick' is assigned a value but never used.","'handleClose' is assigned a value but never used.","'useCallback' is defined but never used.","'Stream' is defined but never used.","'FormControlLabel' is defined but never used.","'Grid' is defined but never used.","'Icon' is defined but never used.","'TextField' is defined but never used.","'Tooltip' is defined but never used.","'HighlightAltIcon' is defined but never used.","'PlayCircleIcon' is defined but never used.","'FormatShapesIcon' is defined but never used.","'LineStyleIcon' is defined but never used.","'HdrAutoIcon' is defined but never used.","'CenterFocusStrongIcon' is defined but never used.","'fontSize' is defined but never used.","'TesseractBlock' is defined but never used.","'setCropHeightPercent' is assigned a value but never used.","'cameras' is assigned a value but never used.","'setCameras' is assigned a value but never used.","'text' is assigned a value but never used.","'onStyleChanged' is assigned a value but never used.","react-hooks/exhaustive-deps","React Hook useEffect has missing dependencies: 'cropArea', 'props', and 'updateCropData'. Either include them or remove the dependency array. However, 'props' will change when *any* prop changes, so the preferred fix is to destructure the 'props' object outside of the useEffect call and refer to those specific props inside useEffect.","ArrayExpression",["91"],"React Hook useEffect has a missing dependency: 'cropArea'. Either include it or remove the dependency array.",["92"],"React Hook useEffect has a missing dependency: 'initialize'. Either include it or remove the dependency array.",["93"],"React Hook useEffect has a missing dependency: 'playVideo'. Either include it or remove the dependency array.",["94"],"jsx-a11y/alt-text","img elements must have an alt prop, either with meaningful text, or an empty string for decorative images.","JSXOpeningElement","no-global-assign","no-unsafe-negation",{"desc":"95","fix":"96"},{"desc":"97","fix":"98"},{"desc":"99","fix":"100"},{"desc":"101","fix":"102"},"Update the dependencies array to be: [autoMode, cropArea, props, updateCropData]",{"range":"103","text":"104"},"Update the dependencies array to be: [cropArea, videoSize]",{"range":"105","text":"106"},"Update the dependencies array to be: [initialize]",{"range":"107","text":"108"},"Update the dependencies array to be: [playVideo, scenario]",{"range":"109","text":"110"},[14491,14501],"[autoMode, cropArea, props, updateCropData]",[17071,17082],"[cropArea, videoSize]",[18072,18074],"[initialize]",[18235,18245],"[playVideo, scenario]"]